{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ml_deploy\n",
    "\n",
    "The ml_deploy package provides a production framework for machine learning models. The platform's emphasis is on defining an objective for a model, tracking the data used for training and predicting, and tracking performance against that goal as your model evolves. This cheat sheet shows how to set up a job using ml_deploy. \n",
    "\n",
    "ml_deploy has a dedicated data model (see [link](https://docs.google.com/spreadsheets/d/1O52-SKVCe_zf_kHttzB7OMM9FeTCGbp1YGck-EzK6SE/edit?usp=sharing)). \n",
    "\n",
    "## Process\n",
    "![ml_deploy Process](ml_deploy_process.PNG)\n",
    "\n",
    "## Data Model Objects\n",
    "### Model\n",
    "At the very highest level is the __model__ object. These are stored in the __ml_deploy_models__ table. A model is the abstract thing which you are modeling. The underlying model parameters might change, the coefficients might change, but this fundamental concept should be immutable.\n",
    "\n",
    "### Model Version\n",
    "As our approach to modeling something evolves, we might want to change the literal model being used for predictions or scoring. For example, we might change the optimization algorithms for an `sklearn.linearregression.LogisticRegression` model, or switch to an entirely new model, while still modeling the same outcome. These changes are referred to as __model_versions__, and are stored in the __ml_deploy_model_versions__ table. One __model__ may have one or more __model_versions__.\n",
    "\n",
    "#### Serialized Model Versions\n",
    "When a new __model_version__ is defined, it is saved as a serialized object for easy reference in the future. This is currently handled by the S3_StoredModelUtility class.\n",
    "\n",
    "### Fitted Model\n",
    "An essential part of putting a model into production is training and retraining your __model_version__. Each time a __model_version__ is trained, a new __fitted_model__ is created. One __model_version__ may have one or more __fitted_models__. Each __fitted_model__ is stored with a mutable set of performance scores.\n",
    "\n",
    "#### Fitted Model Versions\n",
    "When a new __fitted_model__ is defined, it is saved as a serialized object for easy reference in the future. This is currently handled by the S3_StoredModelUtility class.\n",
    "\n",
    "### Training Data\n",
    "The data used to train every __fitted_model__ is stored in the __ml_deploy_training_data__ table. There should be one set of training data per __fitted_model__. The raw data, preprocessed data, testing_date, and test indicator are captured.\n",
    "\n",
    "### Predictions\n",
    "When a __fitted_model__ is used to generate predictions and probabilities, the results are stored in the __ml_deploy_predictions__ table. The raw data, preprocessed data, prediction date, prediction, probability, and target id of the scored record are captured. \n",
    "\n",
    "### Results\n",
    "For every prediction that is made, an actual result is captured in the __ml_deploy_results__ table. The provided result data set is associated with the last prediction set via a target id field.\n",
    "\n",
    "### Result Snapshots\n",
    "Result sets can be snapshotted over time. This is useful for showing how your model improved over time with additional training and tweaks. \n",
    "\n",
    "## To Do\n",
    "* Add features to automatically generate reporting and data visualization datasets.\n",
    "* Add in additional table integrity validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The ml_deploy class requires the following inputs:\n",
    "* sql_alchemy_engine - A SQLAlchemy.Engine object. This is used to run queries against the database.\n",
    "* schema - Probably going to become an optional keyword argument. Specifies the schema in which the ml_deploy data model has been initialized.\n",
    "* store_model_utils_obj - A ml_deploy.StoredModelUtils subclass (currently only S3_StoredModelUtils exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ml_deploy.ml_deploy import MLDeploy, TestUtils, Evaluator\n",
    "from ml_deploy.stored_model_utils import S3_StoredModelUtils, StoredModelUtils\n",
    "from ml_deploy.models import create_data_model\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pandas import read_sql\n",
    "import os\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "'''\n",
    "# -= Postgres example =-\n",
    "# create sql_alchemy_engine object\n",
    "username = 'analytics'\n",
    "password = os.getenv('red-pw')\n",
    "host = 'dw-production.ucoachapp.com'\n",
    "port = 5439\n",
    "database = 'itkdw'\n",
    "\n",
    "template = 'postgresql+psycopg2://{username}:{password}@{host}:{port}/{database}'\n",
    "conn_string = template.format(username=username,\n",
    "                              password=password,\n",
    "                              host=host,\n",
    "                              port=port,\n",
    "                              database=database)\n",
    "\n",
    "sa_engine = create_engine(conn_string)\n",
    "\n",
    "s3_access = os.getenv('s3-access')\n",
    "s3_secret = os.getenv('s3-secret')\n",
    "bucket = 'ml-deploy'\n",
    "s3_smu = S3_StoredModelUtils(s3_access, s3_secret, bucket)\n",
    "'''\n",
    "\n",
    "sa_engine = create_engine('sqlite:///:memory:')\n",
    "create_data_model(sa_engine)\n",
    "smu = StoredModelUtils(mkdtemp())\n",
    "\n",
    "# create instnace of ML_Deploy\n",
    "ml_deploy = MLDeploy(sqlalchemy_engine=sa_engine,\n",
    "                     stored_model_utils_obj=smu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new model\n",
    "After defining the name, type, model object, and model parameters, use the `ml_deploy.store_new_model()` method to create a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = 'Test Engagement Model'\n",
    "model_type = 'engagement'\n",
    "model_obj = LogisticRegression()\n",
    "model_params = model_obj.get_params()\n",
    "\n",
    "# store new model\n",
    "model = ml_deploy.store_new_model(model_name=model_name,\n",
    "                                  model_type=model_type,\n",
    "                                  model_obj=model_obj,\n",
    "                                  model_params=model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ml_deploy.Model attributes\n",
    "The `ml_deploy.store_new_model()` function returns a saved version of the object. It containes the following useful attributes:\n",
    "\n",
    "* `model.model` - A reference to the actual model object.\n",
    "* `model.model_id` - The __id__ value for the model stored in the __ml_deploy_models__ table.\n",
    "* `model.model_name` - The given name of the model. Must be unique!\n",
    "* `model.model_type` - The generic type of the model. Used for comparing models.\n",
    "* `model.model_version_id` - The __id__ of the ml_deploy.Model object in the __ml_deploy_model_versions__ table.\n",
    "* `model.model_version_uuid` - A __uuid__ for the ml_deploy.Model object in the __ml_deploy_model_version__ table.\n",
    "* `model.model_version` - A useful indicator of the __model_version__ iteration of the current __model__.\n",
    "\n",
    "If your model is trained, the following attributes will be set:\n",
    "* `model.fitted_model_id` - The __id__ of the ml_deploy.Model object in the __ml_deploy_fitted_models__ table.\n",
    "* `model.fitted_model_uuid` - A __uuid__ for the ml_deploy.Model object in the __ml_deploy_fitted_models__ table.\n",
    "* `model.fitted_model_version` - A useful indicator of the __fitted_model__ iteration of the current __model_version__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id > 1\n",
      "model_version > 1\n",
      "fitted_model_uuid > None\n"
     ]
    }
   ],
   "source": [
    "print('model_id >', model.model_id)\n",
    "print('model_version >', model.model_version)\n",
    "print('fitted_model_uuid >', model.fitted_model_uuid) # 'None', since this model hasn't been fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating a Model Version\n",
    "If you ever want to change some fundamental parameter of your model, you can make changes directly to the __ml_deploy.model__\n",
    "attribute, and save them with the `ml_deploy.store_model_version()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updated_model_obj = LogisticRegression(solver='lbfgs')\n",
    "model.model = updated_model_obj\n",
    "updated_model_params = model.model.get_params()\n",
    "model = ml_deploy.store_model_version(model, model_params=updated_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "### Querying the data model\n",
    "It is possible to query the data models via the __ml_deploy.query_utils__ class. The methods in this class are straightforward, and it's probably best to stick to the ones that start with _get_. Some useful starters are:\n",
    "* `ml_deploy.query_utils.get_models()` - returns all stored __models__ as a pandas DataFrame.\n",
    "* `ml_deploy.query_utils.get_model_versions(model_id=None)` - returns all stored __model_versions__ as a pandas DataFrame. Limits to ones associated with the optional __model_id__ value.\n",
    "* `ml_deploy.query_utils.get_fitted_models(model_version_id=None)` - returns all stored __fitted_models__ as a pandas DataFrame. Limits the ones associated with the optional __model_version_id__ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>uuid</th>\n",
       "      <th>model_id</th>\n",
       "      <th>version</th>\n",
       "      <th>parameters</th>\n",
       "      <th>production_version</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5d9041d8-aef6-425b-9def-8d03ad279110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"C\": 1.0, \"class_weight\": null, \"dual\": false...</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-08-29 00:49:55.252226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8595f86e-afd8-4ad5-89b4-ff9ba1364f6a</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{\"C\": 1.0, \"class_weight\": null, \"dual\": false...</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-08-29 00:50:07.138556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                  uuid  model_id  version  \\\n",
       "0   1  5d9041d8-aef6-425b-9def-8d03ad279110         1        1   \n",
       "1   2  8595f86e-afd8-4ad5-89b4-ff9ba1364f6a         1        2   \n",
       "\n",
       "                                          parameters  production_version  \\\n",
       "0  {\"C\": 1.0, \"class_weight\": null, \"dual\": false...               False   \n",
       "1  {\"C\": 1.0, \"class_weight\": null, \"dual\": false...               False   \n",
       "\n",
       "                  created_at  \n",
       "0 2018-08-29 00:49:55.252226  \n",
       "1 2018-08-29 00:50:07.138556  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = ml_deploy.query_utils.get_models()\n",
    "\n",
    "model_version_df = ml_deploy.query_utils.get_model_versions(model.model_id)\n",
    "model_version_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving existing models\n",
    "Stored models can be retrieved via the following methods:\n",
    "* `ml_deploy.retrieve_model_version(model_version_id)` - Given a model_version_id, this method will return the associated unfit MLDeployModel object.\n",
    "* `ml_deploy.retrieve_fitted_model(fitted_model_id)` - Given a fitted_model_id, this method will return the associated fitted MLDeployModel object.\n",
    "* `ml_deploy.retrieve_production_model(model_id)` - Given a model_id, this method will return the associated fitted production MLDeployModel object. A given __model__ can only have one production __fitted_model__ at a time. By default, this will be the most recently created fitted model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old model version id> 1\n",
      "old model fitted id > None\n",
      "current unfitted model version id > 2\n"
     ]
    }
   ],
   "source": [
    "old_model = ml_deploy.retrieve_model_version(1)\n",
    "print('old model version id>', old_model.model_version_id)\n",
    "print('old model fitted id >', old_model.fitted_model_id) # None, since the model has not yet been fitted\n",
    "\n",
    "new_model = ml_deploy.retrieve_model_version(2)\n",
    "print('current unfitted model version id >', new_model.model_version_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "The getting and preprocessing of data is not handled by ml_deploy. The only requirements are that you have a DataFrame for your training data, and your preprocessing function returns exactly one DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from oa_jobs.lib.oa.query import AWS_Query\n",
    "from os import getenv\n",
    "\n",
    "aws = AWS_Query(None, 'itkdw', getenv('red-pw'))\n",
    "\n",
    "def get_training_data():\n",
    "    sql = '''\n",
    "    select student_uuid\n",
    "        ,case\n",
    "          when first_contact_date is null then total_comm_outgoing\n",
    "          else total_comm_outgoing_pre_contact\n",
    "        end as contact_outreaches\n",
    "        ,case\n",
    "          when first_contact_date is null then datediff(day, first_outgoing_comm_date, getdate())\n",
    "          else days_outreach_to_contact\n",
    "        end as days_to_contact\n",
    "        ,case\n",
    "            when first_contact_date is not null then 1\n",
    "            else 0\n",
    "        end as contacted\n",
    "              \n",
    "    from vresearch_engagement_summary\n",
    "    \n",
    "    where first_comm_sender_role = 'coach'\n",
    "        and sdp = 'PSC'\n",
    "        \n",
    "    limit 1000\n",
    "    '''\n",
    "    return aws.read(sql)\n",
    "\n",
    "def preprocess(input_df):\n",
    "    input_df['c'] = 1\n",
    "    input_df['days_to_contact'] = input_df['days_to_contact'].fillna(0)\n",
    "    return input_df\n",
    "\n",
    "# get training data\n",
    "training_df = get_training_data()\n",
    "\n",
    "# preprocess data\n",
    "preproc_df = preprocess(training_df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ml_deploy.TestUtils\n",
    "ml_deploy provides a special class specifically for getting selecting a test subset for your data (`TestUtils.get_test_ind()`), as well as a custom version of `TestUtils.train_test_split`. The additional utility provided by these methods is utilized by the ml_deploy data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get __test__ field\n",
    "test_utils = TestUtils()\n",
    "preproc_df  = test_utils.get_test_ind(preproc_df)\n",
    "preproc_df.head()\n",
    "\n",
    "# get train / test split\n",
    "feature_cols = ['c', 'contact_outreaches', 'days_to_contact']\n",
    "label_col = 'contacted'\n",
    "X_train, X_test, y_train, y_test = test_utils.train_test_split(preproc_df ,\n",
    "                                                               feature_cols=feature_cols,\n",
    "                                                               label_col=label_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training your model\n",
    "Because your model object is exposed directly as the .model attribute, you can use whatever method is required to train it once you have your train & test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance\n",
    "The ml_deploy.Evaluator class provides a simple class for evaluating model performance. Simply pass it your predicted and test label values, and it will return a dictionary of performance results. Be default, it will evaluate the Percision, Recall, and Accuracy of your model. This class can be inherited and modified to include different measures. \n",
    "\n",
    "Because the emphasis is on providing reporting and data visaulization on the performance of your models over time, one assumption is that the evaluation metrics have scores bounded between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.model.predict(X_test)\n",
    "evaluator = Evaluator(y_pred, y_test)\n",
    "performance = evaluator.get_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing a fitted model\n",
    "Once your model has been fitted, you can save it to the __ml_deploy_fitted_models__ table and save a serialized version via the `ml_deploy.store_fitted_model()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ml_deploy.store_fitted_model(model, performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing training data\n",
    "Every __fitted_model__ object should have corresponding data in the __ml_deploy_training_data__ table. To store the data used to train your model, use the `ml_deploy.store_training_data()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_deploy.store_training_data(model_obj=model,\n",
    "                              training_df=training_df,\n",
    "                              preproc_df=preproc_df,\n",
    "                              target_col='student_uuid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions\n",
    "Once you have a trained model that has been stored in the __ml_deploy_fitted_models__ table and as a serialized file, you can retrieve it and make predictions.\n",
    "\n",
    "## Retrieving your model\n",
    "The first step will typically be to retrieve your model via the `ml_deploy.retrieve_model()` method. This method requires a _model_id_ value, but can also be supplied with _model_version_id_ and _fitted_model_id_ values. If those values are not provided, it will default to the most recent __model_version__ and / or __fitted_model_id__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_id = 1\n",
    "model = ml_deploy.retrieve_production_model(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get your prediction data and apply your preprocessing function\n",
    "The query to get the set of data that you want to score will likely be different than the one used to train your data. It may or may not utilize the same preprocessing method.\n",
    "\n",
    "### Important note\n",
    "Be sure to include some unique identifier for the record for which you are deriving a prediction or probability. This will populate in the 'target_id' column in __ml_deploy_predictions__ and is used for updating the __ml_deploy_results__ table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction_data():\n",
    "    sql = '''\n",
    "    select stu_uuid\n",
    "      ,sum(case when comm.sender_role = 'coach' then 1 else 0 end) as contact_outreaches\n",
    "      ,datediff(day, coalesce(ustu.first_outgoing_comm_date, ustu.sf_createddate), getdate()) as days_to_contact\n",
    "      ,contacted\n",
    "        \n",
    "    from ucoach_students_all ustu\n",
    "        \n",
    "      left outer join ucoach_communications comm\n",
    "      on ustu.stu_uuid = comm.student_uuid\n",
    "        \n",
    "    where ustu.sdp='PSC'\n",
    "      and\n",
    "        (\n",
    "          (\n",
    "            ustu.first_outgoing_comm_date is null\n",
    "            and datediff(day, sf_createddate, getdate()) < 90\n",
    "          )\n",
    "          or datediff(day, ustu.last_communication_date, getdate()) < 45\n",
    "        )\n",
    "        \n",
    "    group by 1, 3, 4\n",
    "    order by stu_uuid\n",
    "    limit 100;\n",
    "    '''\n",
    "    return aws.read(sql)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_data_df = get_prediction_data()\n",
    "proc_prediction_data_df = preprocess(prediction_data_df.copy())\n",
    "feature_cols = ['c', 'contact_outreaches', 'days_to_contact']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions and get probability scores\n",
    "__ml_deploy__ is set up to capture both binary predictions and their corresponding probability scores. Since your model object is exposed directly as the `ml_deploy.model` attribute, you can use the appropriate method to return the probability and prediction values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.model.predict(proc_prediction_data_df[feature_cols])\n",
    "prob = model.model.predict_proba(proc_prediction_data_df[feature_cols])[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing predictions\n",
    "Once you've created your predictions, you'll want to store them in the __ml_deploy_predictions__ table. This can be done via the `ml_deploy.store_prediction_data()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_deploy.store_prediction_data(model_obj=model,\n",
    "                                input_df=prediction_data_df,\n",
    "                                preproc_df=proc_prediction_data_df,\n",
    "                                predictions=pred,\n",
    "                                probabilities=prob,\n",
    "                                target_col='stu_uuid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing your results\n",
    "After you've made your predictions, you'll want to capture some actual results to evaluate your model's performance.\n",
    "\n",
    "## Fetch result data\n",
    "The query used to fetch your actual result data may or may not be the same as the one used to get your prediction dataset. \n",
    "\n",
    "### Important note\n",
    "The result DataFrame should have two columns:\n",
    "* `target_id`: the unique id of the record that was scored. This should align with the field passed to the 'target_col' key word argument used in the `ml_deploy.store_prediction_data` method.\n",
    "* `result`: this should be the actual 1 or 0 outcome that you are attempting to predict with your model. \n",
    "\n",
    "If your result dataframe is organized or typed differently, it cannot be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing results\n",
    "Pass the `ml_deploy` object used to make the last round of predictions, along with the `new_results_df` to the `ml_deploy.update_results()` method. This will update the predictions and results in the __ml_deploy_results__ table, which will serve as the primary source for evaluating your model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ml_deploy.ml_deploy:starting result processing\n",
      "INFO:ml_deploy.ml_deploy:processing input results dataframe\n",
      "INFO:ml_deploy.ml_deploy:getting latest predictions\n",
      "INFO:ml_deploy.ml_deploy:initializing new result dataframe\n",
      "INFO:ml_deploy.ml_deploy:generating insert orms\n",
      "INFO:ml_deploy.ml_deploy:deleting existing results for updated records\n",
      "INFO:ml_deploy.ml_deploy:inserting new and updated records\n",
      "INFO:ml_deploy.ml_deploy:complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>prediction_id</th>\n",
       "      <th>result_prediction</th>\n",
       "      <th>result_probability</th>\n",
       "      <th>result</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.540014e-14</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-29 00:54:16.221279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.331906e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-29 00:54:16.221279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9.926459e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-29 00:54:16.221279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.674052e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-29 00:54:16.221279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7.766961e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-29 00:54:16.221279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  model_id  prediction_id  result_prediction  result_probability  result  \\\n",
       "0   1         1              1                  0        2.540014e-14       1   \n",
       "1   2         1              2                  1        6.331906e-01       0   \n",
       "2   3         1              3                  1        9.926459e-01       0   \n",
       "3   4         1              4                  0        2.674052e-01       0   \n",
       "4   5         1              5                  1        7.766961e-01       1   \n",
       "\n",
       "                  created_at  \n",
       "0 2018-08-29 00:54:16.221279  \n",
       "1 2018-08-29 00:54:16.221279  \n",
       "2 2018-08-29 00:54:16.221279  \n",
       "3 2018-08-29 00:54:16.221279  \n",
       "4 2018-08-29 00:54:16.221279  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_deploy.update_results(model, prediction_data_df, 'stu_uuid', 'contacted')\n",
    "\n",
    "results_df = ml_deploy.query_utils.get_results(model_id=1)\n",
    "results_df.drop('target_id', 1, inplace=True)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking a Result Snapshot\n",
    "You can take a snapshot of your data by running the `ml_deploy.create_results_snapshot()` method. This will save the current result set along with a timestamp and snapshot version in the `ml_deploy_result_snapshots` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_deploy.create_results_snapshot(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
